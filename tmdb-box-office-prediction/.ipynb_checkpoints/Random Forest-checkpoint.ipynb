{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Kaggle Competition - TMDB Box Office Prediction using Random forest</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Movie wallpaper](./wall_paper.jpg) *pc : wallpaperaccess.com*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "I am writing this post to explain how to use random forest for prediction. I am using [Kaggles TMDB Box Office](https://www.kaggle.com/c/tmdb-box-office-prediction) data for this.\n",
    "\n",
    "In a world… where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's \"You had me at 'Hello.'\" For others, the trailer falls short of expectations and you think \"What we have here is a failure to communicate.\"\n",
    "\n",
    "In this competition, you're presented with metadata on over 7,000 past films from The Movie Database to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "# Modeling Libraries\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This setting is to display all the columns in the notebook.\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = pd.read_csv('dataset/train.csv'),pd.read_csv('dataset/test.csv')\n",
    "train.index = train['id']\n",
    "test.index = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg</td>\n",
       "      <td>[{'name': 'Paramount Pictures', 'id': 4}, {'na...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>2/20/15</td>\n",
       "      <td>93.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "      <td>12314651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>/w9Z7A0GHEhIp7etpj0vyKOeU1Wx.jpg</td>\n",
       "      <td>[{'name': 'Walt Disney Pictures', 'id': 2}]</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>8/6/04</td>\n",
       "      <td>113.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "      <td>95149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>/lIv1QinFqz4dlp5U4lQ6HaiskOZ.jpg</td>\n",
       "      <td>[{'name': 'Bold Films', 'id': 2266}, {'name': ...</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>10/10/14</td>\n",
       "      <td>105.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "      <td>13092000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
       "      <td>http://kahaanithefilm.com/</td>\n",
       "      <td>tt1821480</td>\n",
       "      <td>hi</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>/aTXRaPrWSinhcmCrcfJK17urp3F.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'iso_3166_1': 'IN', 'name': 'India'}]</td>\n",
       "      <td>3/9/12</td>\n",
       "      <td>122.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
       "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
       "      <td>16000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt1380152</td>\n",
       "      <td>ko</td>\n",
       "      <td>마린보이</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>/m22s7zvkVFDU9ir56PiiqIEWFdT.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'iso_3166_1': 'KR', 'name': 'South Korea'}]</td>\n",
       "      <td>2/5/09</td>\n",
       "      <td>118.0</td>\n",
       "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marine Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
       "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
       "      <td>3923970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                              belongs_to_collection    budget  \\\n",
       "id                                                                    \n",
       "1    1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
       "2    2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "3    3                                                NaN   3300000   \n",
       "4    4                                                NaN   1200000   \n",
       "5    5                                                NaN         0   \n",
       "\n",
       "                                               genres  \\\n",
       "id                                                      \n",
       "1                      [{'id': 35, 'name': 'Comedy'}]   \n",
       "2   [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "3                       [{'id': 18, 'name': 'Drama'}]   \n",
       "4   [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
       "5   [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
       "\n",
       "                             homepage    imdb_id original_language  \\\n",
       "id                                                                   \n",
       "1                                 NaN  tt2637294                en   \n",
       "2                                 NaN  tt0368933                en   \n",
       "3   http://sonyclassics.com/whiplash/  tt2582802                en   \n",
       "4          http://kahaanithefilm.com/  tt1821480                hi   \n",
       "5                                 NaN  tt1380152                ko   \n",
       "\n",
       "                              original_title  \\\n",
       "id                                             \n",
       "1                     Hot Tub Time Machine 2   \n",
       "2   The Princess Diaries 2: Royal Engagement   \n",
       "3                                   Whiplash   \n",
       "4                                    Kahaani   \n",
       "5                                       마린보이   \n",
       "\n",
       "                                             overview  popularity  \\\n",
       "id                                                                  \n",
       "1   When Lou, who has become the \"father of the In...    6.575393   \n",
       "2   Mia Thermopolis is now a college graduate and ...    8.248895   \n",
       "3   Under the direction of a ruthless instructor, ...   64.299990   \n",
       "4   Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936   \n",
       "5   Marine Boy is the story of a former national s...    1.148070   \n",
       "\n",
       "                         poster_path  \\\n",
       "id                                     \n",
       "1   /tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg   \n",
       "2   /w9Z7A0GHEhIp7etpj0vyKOeU1Wx.jpg   \n",
       "3   /lIv1QinFqz4dlp5U4lQ6HaiskOZ.jpg   \n",
       "4   /aTXRaPrWSinhcmCrcfJK17urp3F.jpg   \n",
       "5   /m22s7zvkVFDU9ir56PiiqIEWFdT.jpg   \n",
       "\n",
       "                                 production_companies  \\\n",
       "id                                                      \n",
       "1   [{'name': 'Paramount Pictures', 'id': 4}, {'na...   \n",
       "2         [{'name': 'Walt Disney Pictures', 'id': 2}]   \n",
       "3   [{'name': 'Bold Films', 'id': 2266}, {'name': ...   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "\n",
       "                                 production_countries release_date  runtime  \\\n",
       "id                                                                            \n",
       "1   [{'iso_3166_1': 'US', 'name': 'United States o...      2/20/15     93.0   \n",
       "2   [{'iso_3166_1': 'US', 'name': 'United States o...       8/6/04    113.0   \n",
       "3   [{'iso_3166_1': 'US', 'name': 'United States o...     10/10/14    105.0   \n",
       "4             [{'iso_3166_1': 'IN', 'name': 'India'}]       3/9/12    122.0   \n",
       "5       [{'iso_3166_1': 'KR', 'name': 'South Korea'}]       2/5/09    118.0   \n",
       "\n",
       "                                     spoken_languages    status  \\\n",
       "id                                                                \n",
       "1            [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "2            [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "3            [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "4   [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "5            [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]  Released   \n",
       "\n",
       "                                              tagline  \\\n",
       "id                                                      \n",
       "1   The Laws of Space and Time are About to be Vio...   \n",
       "2   It can take a lifetime to find true love; she'...   \n",
       "3     The road to greatness can take you to the edge.   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "\n",
       "                                       title  \\\n",
       "id                                             \n",
       "1                     Hot Tub Time Machine 2   \n",
       "2   The Princess Diaries 2: Royal Engagement   \n",
       "3                                   Whiplash   \n",
       "4                                    Kahaani   \n",
       "5                                 Marine Boy   \n",
       "\n",
       "                                             Keywords  \\\n",
       "id                                                      \n",
       "1   [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
       "2   [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "3   [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
       "4   [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
       "5                                                 NaN   \n",
       "\n",
       "                                                 cast  \\\n",
       "id                                                      \n",
       "1   [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
       "2   [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "3   [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
       "4   [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
       "5   [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
       "\n",
       "                                                 crew   revenue  \n",
       "id                                                               \n",
       "1   [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651  \n",
       "2   [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435  \n",
       "3   [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000  \n",
       "4   [{'credit_id': '52fe48779251416c9108d6eb', 'de...  16000000  \n",
       "5   [{'credit_id': '52fe464b9251416c75073b43', 'de...   3923970  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many columns has list of dictionaries as a value, we need parse those column to get the dat ain tabular format. below are some of the example of such columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am cleaning the revenue and budget data as mentioned in the kaggle kernel \n",
    "# https://www.kaggle.com/zero92/tmdb-prediction\n",
    "\n",
    "train.loc[train['id'] == 16,'revenue'] = 192864         \n",
    "train.loc[train['id'] == 90,'budget'] = 30000000                  \n",
    "train.loc[train['id'] == 118,'budget'] = 60000000       \n",
    "train.loc[train['id'] == 149,'budget'] = 18000000       \n",
    "train.loc[train['id'] == 313,'revenue'] = 12000000       \n",
    "train.loc[train['id'] == 451,'revenue'] = 12000000      \n",
    "train.loc[train['id'] == 464,'budget'] = 20000000       \n",
    "train.loc[train['id'] == 470,'budget'] = 13000000       \n",
    "train.loc[train['id'] == 513,'budget'] = 930000         \n",
    "train.loc[train['id'] == 797,'budget'] = 8000000        \n",
    "train.loc[train['id'] == 819,'budget'] = 90000000       \n",
    "train.loc[train['id'] == 850,'budget'] = 90000000       \n",
    "train.loc[train['id'] == 1007,'budget'] = 2              \n",
    "train.loc[train['id'] == 1112,'budget'] = 7500000       \n",
    "train.loc[train['id'] == 1131,'budget'] = 4300000        \n",
    "train.loc[train['id'] == 1359,'budget'] = 10000000       \n",
    "train.loc[train['id'] == 1542,'budget'] = 1             \n",
    "train.loc[train['id'] == 1570,'budget'] = 15800000       \n",
    "train.loc[train['id'] == 1571,'budget'] = 4000000        \n",
    "train.loc[train['id'] == 1714,'budget'] = 46000000       \n",
    "train.loc[train['id'] == 1721,'budget'] = 17500000       \n",
    "train.loc[train['id'] == 1865,'revenue'] = 25000000      \n",
    "train.loc[train['id'] == 1885,'budget'] = 12             \n",
    "train.loc[train['id'] == 2091,'budget'] = 10             \n",
    "train.loc[train['id'] == 2268,'budget'] = 17500000       \n",
    "train.loc[train['id'] == 2491,'budget'] = 6              \n",
    "train.loc[train['id'] == 2602,'budget'] = 31000000       \n",
    "train.loc[train['id'] == 2612,'budget'] = 15000000       \n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000      \n",
    "train.loc[train['id'] == 2801,'budget'] = 10000000       \n",
    "train.loc[train['id'] == 335,'budget'] = 2 \n",
    "train.loc[train['id'] == 348,'budget'] = 12\n",
    "train.loc[train['id'] == 470,'budget'] = 13000000 \n",
    "train.loc[train['id'] == 513,'budget'] = 1100000\n",
    "train.loc[train['id'] == 640,'budget'] = 6 \n",
    "train.loc[train['id'] == 696,'budget'] = 1\n",
    "train.loc[train['id'] == 797,'budget'] = 8000000 \n",
    "train.loc[train['id'] == 850,'budget'] = 1500000\n",
    "train.loc[train['id'] == 1199,'budget'] = 5 \n",
    "train.loc[train['id'] == 1282,'budget'] = 9              \n",
    "train.loc[train['id'] == 1347,'budget'] = 1\n",
    "train.loc[train['id'] == 1755,'budget'] = 2\n",
    "train.loc[train['id'] == 1801,'budget'] = 5\n",
    "train.loc[train['id'] == 1918,'budget'] = 592 \n",
    "train.loc[train['id'] == 2033,'budget'] = 4\n",
    "train.loc[train['id'] == 2118,'budget'] = 344 \n",
    "train.loc[train['id'] == 2252,'budget'] = 130\n",
    "train.loc[train['id'] == 2256,'budget'] = 1 \n",
    "train.loc[train['id'] == 2696,'budget'] = 10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['id'] == 3033,'budget'] = 250 \n",
    "test.loc[test['id'] == 3051,'budget'] = 50\n",
    "test.loc[test['id'] == 3084,'budget'] = 337\n",
    "test.loc[test['id'] == 3224,'budget'] = 4  \n",
    "test.loc[test['id'] == 3594,'budget'] = 25  \n",
    "test.loc[test['id'] == 3619,'budget'] = 500  \n",
    "test.loc[test['id'] == 3831,'budget'] = 3  \n",
    "test.loc[test['id'] == 3935,'budget'] = 500  \n",
    "test.loc[test['id'] == 4049,'budget'] = 995946 \n",
    "test.loc[test['id'] == 4424,'budget'] = 3  \n",
    "test.loc[test['id'] == 4460,'budget'] = 8  \n",
    "test.loc[test['id'] == 4555,'budget'] = 1200000 \n",
    "test.loc[test['id'] == 4624,'budget'] = 30 \n",
    "test.loc[test['id'] == 4645,'budget'] = 500 \n",
    "test.loc[test['id'] == 4709,'budget'] = 450 \n",
    "test.loc[test['id'] == 4839,'budget'] = 7\n",
    "test.loc[test['id'] == 3125,'budget'] = 25 \n",
    "test.loc[test['id'] == 3142,'budget'] = 1\n",
    "test.loc[test['id'] == 3201,'budget'] = 450\n",
    "test.loc[test['id'] == 3222,'budget'] = 6\n",
    "test.loc[test['id'] == 3545,'budget'] = 38\n",
    "test.loc[test['id'] == 3670,'budget'] = 18\n",
    "test.loc[test['id'] == 3792,'budget'] = 19\n",
    "test.loc[test['id'] == 3881,'budget'] = 7\n",
    "test.loc[test['id'] == 3969,'budget'] = 400\n",
    "test.loc[test['id'] == 4196,'budget'] = 6\n",
    "test.loc[test['id'] == 4221,'budget'] = 11\n",
    "test.loc[test['id'] == 4222,'budget'] = 500\n",
    "test.loc[test['id'] == 4285,'budget'] = 11\n",
    "test.loc[test['id'] == 4319,'budget'] = 1\n",
    "test.loc[test['id'] == 4639,'budget'] = 10\n",
    "test.loc[test['id'] == 4719,'budget'] = 45\n",
    "test.loc[test['id'] == 4822,'budget'] = 22\n",
    "test.loc[test['id'] == 4829,'budget'] = 20\n",
    "test.loc[test['id'] == 4969,'budget'] = 20\n",
    "test.loc[test['id'] == 5021,'budget'] = 40 \n",
    "test.loc[test['id'] == 5035,'budget'] = 1 \n",
    "test.loc[test['id'] == 5063,'budget'] = 14 \n",
    "test.loc[test['id'] == 5119,'budget'] = 2 \n",
    "test.loc[test['id'] == 5214,'budget'] = 30 \n",
    "test.loc[test['id'] == 5221,'budget'] = 50 \n",
    "test.loc[test['id'] == 4903,'budget'] = 15\n",
    "test.loc[test['id'] == 4983,'budget'] = 3\n",
    "test.loc[test['id'] == 5102,'budget'] = 28\n",
    "test.loc[test['id'] == 5217,'budget'] = 75\n",
    "test.loc[test['id'] == 5224,'budget'] = 3 \n",
    "test.loc[test['id'] == 5469,'budget'] = 20 \n",
    "test.loc[test['id'] == 5840,'budget'] = 1 \n",
    "test.loc[test['id'] == 5960,'budget'] = 30\n",
    "test.loc[test['id'] == 6506,'budget'] = 11 \n",
    "test.loc[test['id'] == 6553,'budget'] = 280\n",
    "test.loc[test['id'] == 6561,'budget'] = 7\n",
    "test.loc[test['id'] == 6582,'budget'] = 218\n",
    "test.loc[test['id'] == 6638,'budget'] = 5\n",
    "test.loc[test['id'] == 6749,'budget'] = 8 \n",
    "test.loc[test['id'] == 6759,'budget'] = 50 \n",
    "test.loc[test['id'] == 6856,'budget'] = 10\n",
    "test.loc[test['id'] == 6858,'budget'] =  100\n",
    "test.loc[test['id'] == 6876,'budget'] =  250\n",
    "test.loc[test['id'] == 6972,'budget'] = 1\n",
    "test.loc[test['id'] == 7079,'budget'] = 8000000\n",
    "test.loc[test['id'] == 7150,'budget'] = 118\n",
    "test.loc[test['id'] == 6506,'budget'] = 118\n",
    "test.loc[test['id'] == 7225,'budget'] = 6\n",
    "test.loc[test['id'] == 7231,'budget'] = 85\n",
    "test.loc[test['id'] == 5222,'budget'] = 5\n",
    "test.loc[test['id'] == 5322,'budget'] = 90\n",
    "test.loc[test['id'] == 5350,'budget'] = 70\n",
    "test.loc[test['id'] == 5378,'budget'] = 10\n",
    "test.loc[test['id'] == 5545,'budget'] = 80\n",
    "test.loc[test['id'] == 5810,'budget'] = 8\n",
    "test.loc[test['id'] == 5926,'budget'] = 300\n",
    "test.loc[test['id'] == 5927,'budget'] = 4\n",
    "test.loc[test['id'] == 5986,'budget'] = 1\n",
    "test.loc[test['id'] == 6053,'budget'] = 20\n",
    "test.loc[test['id'] == 6104,'budget'] = 1\n",
    "test.loc[test['id'] == 6130,'budget'] = 30\n",
    "test.loc[test['id'] == 6301,'budget'] = 150\n",
    "test.loc[test['id'] == 6276,'budget'] = 100\n",
    "test.loc[test['id'] == 6473,'budget'] = 100\n",
    "test.loc[test['id'] == 6842,'budget'] = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependent Variable - Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(train['revenue'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(train['revenue'],hist=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue is right skewed. Need to take log\n",
    "fig, ax = plt.subplots(figsize = (16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(np.log1p(train['revenue']))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(np.log1p(train['revenue']),hist=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_revenue'] = np.log1p(train['revenue'])\n",
    "train = train.drop(['revenue'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined the train & test dataset as one dataframe for easy preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the dataset for pre-processing\n",
    "\n",
    "train_rows = train.shape[0]\n",
    "\n",
    "combined= train.append(test,ignore_index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Null Values\n",
    "checking null values and try to fill it if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the missing release date and fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['release_date'].isna(),'original_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['original_title']=='Jails, Hospitals & Hip-Hop','release_date']='5/1/00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the 'list of dictionaries' column tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production companies column is in the format of list of dictionaries\n",
    "print(combined['original_title'][1],\" was produced by \\n\",[x['name'] for x in ast.literal_eval(combined['production_companies'][1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are all the columns that needs to be fixed since these contain the dictionary data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_column = ['belongs_to_collection','genres','spoken_languages','Keywords',\n",
    "               'cast','crew','production_companies','production_countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_dict(df,columns):\n",
    "    '''\n",
    "    Converts the dictionary that is stored as string back as dictionary\n",
    "    '''\n",
    "    for col in columns:\n",
    "        df[col] = df[col].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = text_to_dict(combined,dict_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lets convert Dictionary columns to meaning full column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['budget',\n",
    "                    'original_language',\n",
    "                    'popularity',\n",
    "                    'belongs_to_collection',\n",
    "                    'release_date',\n",
    "                    'tagline',\n",
    "                    'genres',\n",
    "                    'cast',\n",
    "                    'production_companies',\n",
    "                    'log_revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combined[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leading Actor\n",
    "\n",
    "From the cast lets extract the first actor which is a leading actor of the flim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Leading actor\n",
    "combined['leading_actor'] = combined.loc[:,'cast'].apply(lambda x : x[0]['name'] if len(x)!=0 else '')\n",
    "combined= combined.drop(['cast'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Production Company\n",
    "From the production company dict lets extract the first production company which is main production company of the flim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting production_companies\n",
    "combined['leading_production'] = combined.loc[:,'production_companies'].apply(lambda x : x[0]['name'] if len(x)!=0  else '')\n",
    "combined= combined.drop(['production_companies'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Genere\n",
    "\n",
    "From the genere dict lets extract the first genere  which is main genere company of the flim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Main genere\n",
    "combined['main_genre'] = combined.loc[:,'genres'].apply(lambda x : x[0]['name'] if len(x)!=0 else '')\n",
    "combined= combined.drop(['genres'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Release Date Features\n",
    "\n",
    "From the release data , extract the year and month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the relase date as date column & extract year\n",
    "\n",
    "combined['year'] = combined['release_date'].apply(lambda x: datetime.strptime(x,'%m/%d/%y').year)\n",
    "combined['month'] = combined['release_date'].apply(lambda x: datetime.strptime(x,'%m/%d/%y').month)\n",
    "combined['year'] = combined['year'].apply(lambda x : x - 100 if x > 2020 else x)\n",
    "\n",
    "combined= combined.drop(['release_date'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Belongs to collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(combined['belongs_to_collection'].apply(lambda x : len(x) if x!={} else 0)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since atmost each is move part of only one collection, create a flag to indicate if the movie belongs to a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['is_collection'] = combined['belongs_to_collection'].apply(lambda x : 1 if x != {} else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also create a column 'collection_name' for the top 1000 movies with collections based on number of movies in a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = pd.DataFrame(combined['belongs_to_collection'].apply(lambda x : x[0]['name'] if x !={} else 'NA').value_counts())\n",
    "movie_collection_list = list(vc.query('belongs_to_collection>1 and belongs_to_collection < 1000').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['collection_name'] = combined['belongs_to_collection'].apply( \n",
    "                                lambda x: x[0]['name'] if (x!={} and x[0]['name'] in movie_collection_list) else 'NA')\n",
    "combined = combined.drop(['belongs_to_collection'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### has tagline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[combined['tagline'].isnull(),'tagline'] = 'NaN'\n",
    "combined['has_tagline'] = combined['tagline'].apply(lambda x : 1 if x != 'NaN' else 0)\n",
    "combined = combined.drop(['tagline'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot encoding - Original_language\n",
    "\n",
    "combined['original_language'] = combined['original_language'].apply(lambda x: x if x == 'en' else 'non_en')\n",
    "\n",
    "en_original_language_fit = OneHotEncoder(handle_unknown='ignore').fit(combined[['original_language']])\n",
    "en_original_language = pd.DataFrame(en_original_language_fit.transform(combined[['original_language']]).toarray())\n",
    "combined= combined.join(en_original_language,rsuffix='_original_language')\n",
    "\n",
    "combined = combined.drop(['original_language'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collection Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Collection Name based on movie count\n",
    "list(combined['collection_name'].value_counts().index)[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot encoding - Collection_name\n",
    "\n",
    "popular_collection = list(combined['collection_name'].value_counts()[1:20].index)\n",
    "\n",
    "combined['collection_name'] = combined['collection_name'].apply(lambda x : x if x in popular_collection else 'other')\n",
    "\n",
    "en_collection_name = pd.DataFrame(OneHotEncoder(handle_unknown='ignore').fit_transform(combined[['collection_name']]).toarray())\n",
    "combined= combined.join(en_collection_name,rsuffix='_collection_name')\n",
    "\n",
    "combined = combined.drop(['collection_name'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot encoding - Month\n",
    "en_month = pd.DataFrame(OneHotEncoder(handle_unknown='ignore').fit_transform(combined[['month']]).toarray())\n",
    "combined= combined.join(en_month,rsuffix='_month')\n",
    "\n",
    "combined = combined.drop(['month'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leading Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot encoding - Leading Actor\n",
    "popular_leading_actor = list(combined['leading_actor'].value_counts()[1:30].index)\n",
    "\n",
    "combined['leading_actor'] = combined['leading_actor'].apply(lambda x : x if x in popular_leading_actor else 'other')\n",
    "\n",
    "en_leading_actor = pd.DataFrame(OneHotEncoder(handle_unknown='ignore').fit_transform(combined[['leading_actor']]).toarray())\n",
    "combined= combined.join(en_leading_actor,rsuffix='_leading_actor')\n",
    "\n",
    "combined = combined.drop(['leading_actor'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main genere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot encoding - Main genre\n",
    "popular_genre  = list(combined['main_genre'].value_counts()[0:15].index)\n",
    "\n",
    "combined['main_genre'] = combined['main_genre'].apply(lambda x : x if x in popular_genre else 'other')\n",
    "\n",
    "en_genre = pd.DataFrame(OneHotEncoder(handle_unknown='ignore').fit_transform(combined[['main_genre']]).toarray())\n",
    "combined= combined.join(en_genre,rsuffix='_main_genre')\n",
    "\n",
    "combined = combined.drop(['main_genre'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leading Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot encoding - Leading Production\n",
    "popular_production = list(combined['leading_production'].value_counts()[1:11].index)\n",
    "\n",
    "combined['leading_production'] = combined['leading_production'].apply(lambda x : 'big_producer' if x in popular_production else 'small_producer')\n",
    "\n",
    "en_production = pd.DataFrame(OneHotEncoder(handle_unknown='ignore').fit_transform(combined[['leading_production']]).toarray())\n",
    "combined= combined.join(en_production,rsuffix='_leading_production')\n",
    "\n",
    "combined = combined.drop(['leading_production'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = combined.loc[:train_rows-1,]\n",
    "test1 = combined.loc[train_rows:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trainX,train_validX,train_trainY,train_validY = train_test_split(train1,train1['log_revenue'],test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trainX = train_trainX.drop(['log_revenue'],axis=1)\n",
    "train_validX = train_validX.drop(['log_revenue'],axis=1)\n",
    "test1 = test1.drop(['log_revenue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(n_estimators=1000,\n",
    "                           n_jobs=-1,\n",
    "                           oob_score=True, \n",
    "                           #random_state=43,\n",
    "                           bootstrap=True,\n",
    "                           min_samples_split=30,\n",
    "                           max_features=0.1)\n",
    "\n",
    "\n",
    "model = regr.fit(train_trainX,train_trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_train_prediction = pd.DataFrame({'Predicted': model.predict(train_trainX),'Actual': train_trainY})\n",
    "\n",
    "# Train Error \n",
    "np.sqrt(metrics.mean_squared_error(train1_train_prediction['Predicted'],train1_train_prediction['Actual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_train_prediction = pd.DataFrame({'Predicted': model.predict(train_validX),'Actual': train_validY})\n",
    "\n",
    "# Valid Error \n",
    "np.sqrt(metrics.mean_squared_error(train1_train_prediction['Predicted'],train1_train_prediction['Actual']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
